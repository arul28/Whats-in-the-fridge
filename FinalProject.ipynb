{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FinalProject.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qxhzV4vQmokV",
        "colab_type": "text"
      },
      "source": [
        "# Fridge Food Detection\n",
        "\n",
        "Sarvesh Somasundaram, Taha Haveliwala, Arul Sharma"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UfmqnOtDmwPQ",
        "colab_type": "text"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Tp731U1k1mI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "!pip install q keras==2.1.6\n",
        "import tensorflow as tf\n",
        "import keras as K\n",
        "print(tf.__version__)\n",
        "print(K.__version__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GGjrSjGVk6JT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "from google.colab import files\n",
        "drive.mount(\"/content/drive\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S-P6JQiok8Rr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.callbacks import Callback\n",
        "from keras.backend import clear_session\n",
        "from keras.models import Model, load_model\n",
        "from keras.layers import Dense, Input, Flatten\n",
        "from keras.applications import ResNet50\n",
        "import pandas as pd\n",
        "\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from collections import Counter\n",
        "\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ZBq-u7Am04V",
        "colab_type": "text"
      },
      "source": [
        "## Model Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tKVBISBrlCPk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_model(mode, model_path = None):\n",
        "\n",
        "    clear_session()\n",
        "\n",
        "    if mode == 'train':\n",
        "        img = Input(shape = (224, 224, 3)) #Setting the input shape of the image\n",
        "\n",
        "        # Importing the model and removing the top layer\n",
        "        model = ResNet50(include_top=False, \n",
        "                          weights='imagenet', \n",
        "                          input_tensor=img, \n",
        "                          input_shape=None, \n",
        "                          pooling='avg')\n",
        "\n",
        "        final_layer = model.layers[-1].output\n",
        "\n",
        "        dense_layer_1 = Dense(128, activation = 'relu')(final_layer) # Adding a final dense layer\n",
        "        output_layer = Dense(8, activation = 'sigmoid')(dense_layer_1) # Adding an output layer with sigmoid activation and 8 outputs\n",
        "        model = Model(input = img, output = output_layer)\n",
        "        \n",
        "        model.trainable = True\n",
        "\n",
        "        set_trainable = False\n",
        "        \n",
        "        # Setting the specified layers as trainable\n",
        "        for layer in model.layers:\n",
        "            if layer.name in ['res5c_branch2b', 'res5c_branch2c', 'activation_97']:\n",
        "                set_trainable = True\n",
        "            if set_trainable:\n",
        "                layer.trainable = True\n",
        "            else:\n",
        "                layer.trainable = False\n",
        "        layers = [(layer, layer.name, layer.trainable) for layer in model.layers]\n",
        "        print(pd.DataFrame(layers, columns=['Layer Type', 'Layer Name', 'Layer Trainable']))\n",
        "          \n",
        "    # This mode is for predicting with the model\n",
        "    elif mode == 'inference':\n",
        "        model = load_model(model_path)\n",
        "    return model\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B82GVRD8lRBj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer = 'adam', loss = 'binary_crossentropy' , metrics = ['accuracy']) # Compiling the model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8aUTkwLjlYdH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def F1_score(y_true, y_pred):\n",
        "    return f1_score(y_true, y_pred, average='samples') # Computes the f1 score which is a metric that measures recall\n",
        "\n",
        "class ComputeF1(Callback):\n",
        "    \n",
        "    def __init__(self):\n",
        "        self.best_f1 = -1\n",
        "        \n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        val_pred = np.round(self.model.predict(self.validation_data[0]))\n",
        "        val_f1 = f1_score(self.validation_data[1], val_pred, average='samples') # Calculating the F1 Score at the end of each epoch to see if the model has improved enough to save\n",
        "        print('Validation Average F1 Score: ', val_f1)\n",
        "        \n",
        "        if val_f1 > self.best_f1:\n",
        "            print('Better F1 Score, Saving model...')\n",
        "            self.model.save('model.h5') # Saving the model\n",
        "            self.best_f1 = val_f1\n",
        "\n",
        "# Processing the images and data from csv file\n",
        "def load_data(df):\n",
        "    \n",
        "    trainX, testX, valX = [], [], []\n",
        "    trainY, testY, valY = [], [], []\n",
        "    \n",
        "    for i in range(len(df)):\n",
        "        \n",
        "        item = df.loc[i][0]\n",
        "        current_label = np.array((df.loc[i])[1:])\n",
        "        \n",
        "        path = os.path.join('/content/drive/My Drive/project/data/augimages2', item)\n",
        "        list_of_imgs = [os.path.join(path, file) for file in os.listdir(path)]\n",
        "        # Splitting the images into train, validation, and test sets\n",
        "        train_set = list_of_imgs[:150]\n",
        "        val_set = list_of_imgs[150:200]\n",
        "        test_set = list_of_imgs[200:]\n",
        "        \n",
        "        for file in train_set:\n",
        "            img = cv2.resize(cv2.cvtColor(cv2.imread(file, 1), cv2.COLOR_BGR2RGB), (224, 224))\n",
        "            trainX.append(img)\n",
        "            trainY.append(current_label)\n",
        "        \n",
        "        for file in val_set:\n",
        "            img = cv2.resize(cv2.cvtColor(cv2.imread(file, 1), cv2.COLOR_BGR2RGB), (224, 224))\n",
        "            valX.append(img)\n",
        "            valY.append(current_label)\n",
        "        \n",
        "        for file in test_set:\n",
        "            img = cv2.resize(cv2.cvtColor(cv2.imread(file, 1), cv2.COLOR_BGR2RGB), (224, 224))\n",
        "            testX.append(img)\n",
        "            testY.append(current_label)\n",
        "            \n",
        "    return (np.array(trainX), np.array(trainY), np.array(testX), \n",
        "            np.array(testY), np.array(valX), np.array(valY))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p1R00LX6ltmV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if __name__ == '__main__':\n",
        "\n",
        "    print('Loading Data...') # Running the load_data function\n",
        "    df = pd.read_csv('/content/drive/My Drive/project/data/annotationsnew.csv') # importing the csv file\n",
        "    print(df)\n",
        "    trainX, trainY, testX, testY, valX, valY = load_data(df)\n",
        "    print('Data Loaded.')\n",
        "\n",
        "    ## Normalization\n",
        "    trainX = trainX.astype(np.float32)\n",
        "    testX = testX.astype(np.float32)\n",
        "    valX = valX.astype(np.float32)\n",
        "\n",
        "    trainY = trainY.astype(np.float32)\n",
        "    testY = testY.astype(np.float32)\n",
        "    valY = valY.astype(np.float32)\n",
        "\n",
        "    # Computing the first F1 score\n",
        "    f1_score_callback = ComputeF1()\n",
        "    model = build_model('train') # Initializing the model\n",
        "\n",
        "    # Training model\n",
        "    model.fit(trainX, trainY, batch_size = 32, epochs = 15, validation_data = (valX, valY), callbacks = [f1_score_callback])\n",
        "\n",
        "    # Compute test F1 Score\n",
        "    model = load_model('model.h5')\n",
        "\n",
        "    score = F1_score(testY, model.predict(testX).round())\n",
        "    print('F1 Score =', score)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XBY3ZtmTmkQ-",
        "colab_type": "text"
      },
      "source": [
        "## Prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bWyp1_T-na79",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# We used this to filter out the log outputs to make it wasier to read\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
        "# These are the categories that the model was trained on\n",
        "categories = ['apple', 'bread', 'brocolli', 'carrot', 'chicken', 'milk', 'orange', 'pork']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tZmIQeB6ndUc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image = Image.open('/content/download.jpg') # opening image\n",
        "new_image = image.resize((224, 224)) # Resizing image to fit our model\n",
        "new_image.save('test.jpg') # Saving new image for testing"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KTTMmQaJl1pY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = build_model('inference', model_path = '/content/model.h5') # Initialzing model\n",
        "\n",
        "img = np.expand_dims(cv2.imread('/content/test.jpg', 1), axis = 0) # Preparing input image\n",
        "\n",
        "prediction = np.round(model.predict(img)[0]) # Running the prediction\n",
        "print(prediction)\n",
        "labels = [categories[idx] for idx, current_prediction in enumerate(prediction) if current_prediction == 1] # Adding the labels\n",
        "print('Prediction:', labels)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}